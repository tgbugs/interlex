-- postgres postgres
DO
$body$
BEGIN
    IF NOT EXISTS ( SELECT * FROM pg_catalog.pg_user
        WHERE usename = 'interlex-api') THEN
        CREATE ROLE "interlex-user" LOGIN
        NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE;
    END IF;
    IF NOT EXISTS ( SELECT * FROM pg_catalog.pg_user
        WHERE usename = 'interlex-admin') THEN
        CREATE ROLE "interlex-admin" LOGIN
        NOSUPERUSER INHERIT NOCREATEDB NOCREATEROLE;
    END IF;
END;
$body$

-- postgres postgres

ALTER ROLE "interlex-admin" SET search_path = interlex, public;
ALTER ROLE "interlex-user" SET search_path = interlex, public;

-- postgres postgres

DROP DATABASE IF EXISTS interlex_test;

-- postgres postgres

CREATE DATABASE interlex_test -- interlex
    WITH OWNER = 'interlex-admin'
    ENCODING = 'UTF8'
    TABLESPACE = pg_default
    LC_COLLATE = 'en_US.utf8'  -- as opposed to 'en_US.UTF-8' for < 10.0 ??
    LC_CTYPE = 'en_US.utf8'
    CONNECTION LIMIT = -1;

-- postgres interlex_test

CREATE EXTENSION uri;  -- keep this on public schema for safety

-- interlex-admin interlex_test

CREATE SCHEMA IF NOT EXISTS interlex;
GRANT CONNECT ON DATABASE interlex_test TO "interlex-user";
GRANT USAGE ON SCHEMA interlex TO "interlex-user";

-- interlex-admin interlex_test

CREATE TABLE groups(
       -- working table to store information awaiting verification
       id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- preferred for 10+
       groupname varchar(40) UNIQUE NOT NULL,
       CHECK (groupname !~* 'ilx_.*')
);

CREATE UNIQUE INDEX groups_lower_index ON groups (lower(groupname));

INSERT INTO groups (groupname) VALUES ('base'),  -- not an org
       -- reserved groups
       -- check these against startswith not == ?? or not
                                      ('latest'),  -- not an org
                                      ('origin'),  -- not an org
                                      ('curated'),
                                      ('reasonable'),  -- terms + edges

                                      -- redirects
                                      ('default'), -- curated

                                      -- util
                                      ('info'),
                                      ('admin'),

                                      -- users
                                      ('tgbugs'),
                                      ('jgrethe'),
                                      ('bandrow'),
                                      ('memartone'),
                                      ('tgillesp'),
                                      ('tgillespie'),

                                      -- orgs
                                      ('NIF'),
                                      ('SciCrunch'),
                                      ('obo'),
                                      ('uberon'),
                                      ('NDA'),
                                      ('MESH'),
                                      ('fsl');


INSERT INTO groups (id, groupname) VALUES (-1, 'curator'),
       -- https://github.com/shouldbee/reserved-usernames/blob/master/reserved-usernames.txt
       -- populate more with with len > 4
       -- make sure user roles are also black liasted here

        -- blackhole
        -- behavior when resolving is to 404
        -- behavior if referenced internally by accident internally?
                                          (-2, 'contributor'),
                                          (-3, 'readable'),
                                          (-4, 'ontologies'),
                                          (-5, 'version'),
                                          (-6, 'versions'),
                                          (-7, 'curie'),
                                          (-8, 'curies'),
                                          (-9, 'prefix'),
                                          (-10, 'prefixes'),
                                          (-11, 'owner'),
                                          (-12, 'banned'),
                                          (-13, 'erased');

CREATE FUNCTION groupname_length_check() returns trigger AS $groupname_length_check$
       BEGIN
           IF (length(NEW.groupname) < 5) THEN
              RAISE exception '% is too short! InterLex usernames and org names must be at least 5 characters long.', NEW.groupname;
           ELSE
              RETURN NEW;
           END IF;
       END;
$groupname_length_check$ language plpgsql;

CREATE TRIGGER groupname_length_check BEFORE INSERT ON groups FOR each row execute procedure groupname_length_check();

 -- ALTER TABLE groups add CONSTRAINT cc__groups__groupname_len_gt_4 CHECK (length(groupname) > 4);
      -- FIXME have to find another way to enforce this since we want _some_ usernames to be shorter
      -- probably do this in the python
      -- prevent the creation of groups with names len < 5
      -- without administrator

/* -- as long as we use serializable isolation (duh) we don't need this table
CREATE TABLE new_users(
       id integer PRIMARY KEY,
       putative_orcid uri UNIQUE NOT NULL,  -- TODO ask to update on failure? also http://dead.interlex.org/ORCID-SIGNUP-REQUIRED
       -- That orcid does not exist!
       orcid_validated boolean DEFAULT FALSE,
       email_validated boolean DEFAULT FALSE,
       CONSTRAINT fk__new_users__id__groups FOREIGN key (id) REFERENCES groups (id) match simple
);
*/

CREATE TABLE user_orcid(
       user_id integer not null,
       orcid uri not null,
       orcid_validated boolean DEFAULT FALSE,
       -- access to their records is managed in orcid tokens
       -- login via orcid https://members.orcid.org/api/integrate/orcid-sign-in
       -- https://members.orcid.org/api/tutorial/get-orcid-id
       CONSTRAINT pk__user_orcid PRIMARY KEY (user_id, orcid),
       CONSTRAINT fk__user_orcid__user_id__groups FOREIGN key (user_id) REFERENCES groups (id) match simple
);

CREATE FUNCTION orcid_complete() RETURNS trigger AS $orcid_complete$
       BEGIN
           -- SELECT * FROM user_emails as ue WHERE ue.user_id = NEW.user_id AND ue.email_validated = TRUE LIMIT 1;
           -- IF FOUND AND NOT OLD.orcid_validated AND NEW.orcid_validated THEN -- only try this the first time
           IF EXISTS (SELECT * FROM user_emails as ue WHERE ue.user_id = NEW.user_id AND ue.email_validated = TRUE LIMIT 1) AND
           NOT OLD.orcid_validated AND NEW.orcid_validated THEN -- only try this the first time
              INSERT INTO users (id, orcid, username)
              SELECT NEW.user_id, NEW.orcid, g.groupname FROM groups AS g WHERE g.id = NEW.user_id;
           END IF;
           RETURN NULL;
       END;
$orcid_complete$ language plpgsql;

CREATE TRIGGER orcid_complete AFTER UPDATE ON user_orcid FOR each row execute procedure orcid_complete();

CREATE TABLE orcid_tokens(
       orcid uri NOT NULL, 
       orcid_auth_code char(6),
       token_type text,
       access_token uuid,
       refresh_token uuid,
       expires_in integer,  -- annoying...
       token_scope text,
);

CREATE TABLE user_emails(
       user_id integer NOT NULL,
       email text UNIQUE NOT NULL,
       email_primary boolean NOT NULL,
       email_validated boolean DEFAULT FALSE,  -- either they click the link or they paste it in somewhere
       -- email + user_id + datetime + valid_for_time + secret -> encrypt it -> put it in a link -> email the link

       -- email_validation_token  -- use the crypto version of this so we don't have to hit the database?
       -- text only option
       -- email_verification_token varchar(40) NOT NULL,  -- TODO how do people do this? on the application side apparently
       -- email_verification_token_expiration timestamp not null DEFAULT CURRENT_TIME + interval '1 hour',
       -- email_verification_email_sent boolean DEFAULT FALSE,
       -- email_verification_link_clicked_time timestamp DEFAULT NULL CHECK NULL OR (email_verification_link_clicked_time < email_verification_token_expiration),
       -- on error we generate a new token and send another email
       CONSTRAINT pk__user_emails PRIMARY KEY (user_id, email),
       CONSTRAINT fk__user_emails__user_id__groups FOREIGN key (user_id) REFERENCES groups (id) match simple
);

CREATE FUNCTION email_complete() RETURNS trigger AS $email_complete$
       BEGIN
           IF EXISTS (SELECT email_validated from user_emails where user_emails.user_id = NEW.user_id AND email_validated = TRUE) AND -- OLD? not u_e?
           NEW.email_validated AND
           EXISTS (SELECT * FROM user_orcid as uo WHERE uo.user_id = NEW.user_id AND uo.orcid_validated = TRUE) THEN
              -- fail on the constraints when trying to insert again rather than trying to be smart here
              INSERT INTO users (id, orcid, username)
              VALUES (NEW.user_id,
                      (SELECT orcid from user_orcid where user_orcid.user_id = NEW.user_id),
                      (SELECT groupname from groups where groups.id = NEW.user_id));
           END IF;
           RETURN NULL;
       END;
$email_complete$ language plpgsql;

CREATE TRIGGER email_complete AFTER UPDATE ON user_emails FOR EACH row execute procedure email_complete();

CREATE TABLE users(
       -- the validated users table, used to isolate validation state and provide a single source of truth
       -- users are only put here when we have authenticated everything
       -- login with orcid only seems like it will be much less hastle but requires us to be a member?
       -- this is NOT the table that manages user permissions

       -- id serial not null,
       -- if you make additions to interlex your user will be preserved even if you delete your account
       -- you can revoke interlex's permission to update your orcid profile, but for the purposes of
       -- provenance your constributions under your username and orcid will be preserved
       -- TODO consider different levels of prov identification?
       -- id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- preferred for 10+
       id integer PRIMARY KEY,
       orcid uri UNIQUE NOT NULL,  -- use orcid oauth NOTE have to do something special for base default curated etc.
       username varchar(40) UNIQUE NOT NULL,  -- e.g. tgbugs  case insensitive via index, limit to 40 chars
       -- email text unique not null,  -- validate with response, this is not used to log you in, this is for prov...
       -- we will only store these after validation and auth but the database can't do that itself
       -- https://members.orcid.org/api/oauth/3legged-oauth
       -- see also https://members.orcid.org/api/workflow/repository#1collect
       -- https://support.orcid.org/knowledgebase/articles/116780-structure-of-the-orcid-identifier&quot
       CONSTRAINT fk__users__id__groups FOREIGN key (id) REFERENCES groups (id) match simple,
       CONSTRAINT fk__users__username__groups FOREIGN key (username) REFERENCES groups (groupname) match simple
);

CREATE TABLE orgs(
       id integer PRIMARY KEY,
       orgname varchar(40) NOT NULL,
       -- note that github has a billing email here as well
       -- and the next step they go to is inviting members
       creator_id integer NOT NULL,
       CONSTRAINT fk__orgs__id__groups FOREIGN key (id) REFERENCES groups (id) match simple,
       CONSTRAINT fk__orgs__orgname__groups FOREIGN key (orgname) REFERENCES groups (groupname) match simple,
       CONSTRAINT fk__orgs__creator_id__users FOREIGN key (creator_id) REFERENCES users (id) match simple
);

CREATE materialized view org_user_view AS SELECT id, username FROM users UNION SELECT id, orgname FROM orgs;

CREATE OR REPLACE FUNCTION idFromGroupname(groupname varchar(40), OUT group_id integer) RETURNS integer AS $idFromGroupname$
       -- FIXME run this off groups not org_user_view?
       BEGIN
           SELECT id INTO STRICT group_id FROM groups as g WHERE g.groupname = idFromGroupname.groupname;
           -- usd STRICT to abort a transaction eary if the user does not exist
       END;
$idFromGroupname$ language plpgsql;

CREATE type user_role AS enum ('admin', 'owner', 'contributor', 'curator', 'banned', 'erased');
       -- users with lower enum value (ie admin is lowest) have more privs
       -- permission is only granted, if there is no permission then users can only view
       -- can use ALTER TYPE to insert new values into enums if we need them, much safer than doing it as a table

       -- erased banned + hide all triples they have added (we never really erase) and remove from users table
       -- banned everything that we know of associated with this user id shall be blocked (ip?) the way interlex is built this should almost never need to happen, their content is preserved
       -- curator      can only approve edges contributed by others for inclusion in a given group
                       -- distinct from contributor to manage the curated group where no one can add to that directly
       -- contributor  can add triples in a given group and can create new uris (may want to split these?)
       -- ? mapping    can create new uris and mappings ??? not clear we need this role as distinct from contributor
       -- ? ontology   can create new ontologies and ontology uris and named versions ??? not clear if this as distinct from contributor
       -- owner        can do anything in a particular group users are owners of their own user identical groups
       -- admin        can do anything in any group

CREATE TABLE user_permissions(
       group_id integer NOT NULL,  -- user or org, initially only granted curator in their user group
       user_id integer NOT NULL,  -- the fkey prevents groups from having any permissions which is important since can't log in as group
       role_id user_role NOT NULL,
       -- TODO references users vs references new_users due to need to erase users?
       CONSTRAINT fk__user_permissions__group_id__groups FOREIGN key (group_id) REFERENCES groups (id) match simple,
       CONSTRAINT fk__user_permissions__user_id__users FOREIGN key (user_id) REFERENCES users (id) match simple
);

CREATE TABLE user_failover_ranks(
       user_id integer NOT NULL,
       rank integer NOT NULL,
       group_id integer NOT NULL DEFAULT 1,  -- curated/default
       CONSTRAINT pk__user_failover_ranks PRIMARY key (user_id, rank),
       CONSTRAINT un__user_failover_ranks UNIQUE (user_id, group_id),
       CONSTRAINT fk__user_failover_ranks__user_id__users FOREIGN key (user_id) REFERENCES users (id) match simple,
       CONSTRAINT fk__user_failover_ranks__other_user_id__users FOREIGN key (group_id) REFERENCES users (id) match simple

);

CREATE type event_type AS enum ('pull requests',
                                -- new term requests vs include requests vs modification requests?
                                'review requests',
                                'changes to terms i track',
                                'changes to ontologies i track'
                                );

CREATE type notification_pref AS enum ('email', 'InterLex feed');
       -- null/none is not recorded and simply removed from the table

CREATE TABLE user_notification_preferences(
       -- include only send
       user_id integer NOT NULL,
       event event_type NOT NULL,
       notification notification_pref NOT NULL,
       CONSTRAINT fk__user_email_preferences__user_id__users FOREIGN key (user_id) REFERENCES users (id) match simple
);

/*
create table user_preferences(
       -- not clear we need this, the data for customization lives a number of different places that
       -- make more operation sense
       user_id integer not null,
       constraint fk__user_preferences__user_id__users foreign key (user_id) references users (id) match simple
);
*/

--

CREATE sequence if NOT exists interlex_ids_seq;

CREATE TABLE interlex_ids(
       -- to display this for a specific user
       -- 1) get the latest qualifier for their user id
       -- 2) get all subjects from existing_ids for this ilx_id
       -- 3) get all triples with matching subjects and where the current default qualifier or the current user qualifier (or other specified qualifiers?)
       -- 4) get the cardinality limited predicates (label, definition, etc) select the most recent
       -- user = latest will take the most recent changes from any qualifier
       -- this does however point out the issue with the qualifiers table: we need a way to know that a change has been made
       -- by a specific user so we can't use the qualifier datetime
       -- we could simply increment the datetime for a user qualifier whenever they make a change
       -- but that would promote old unreleated changes so that doesn't work...

       -- FIXME should not use a sequence since it could create gaps on failures?!
       -- or we only call this when we are 100% sure, but in that case the database doesn't protect us
       id char(7) PRIMARY key DEFAULT LPAD(NEXTVAL('interlex_ids_seq')::text, 7, '0')  -- either uri.interlex.org/base/ilx_1234567 or ilx_1234567
       -- source_iri uri DEFAUL NULL,
       -- TODO for cases where we don't need/want to have a bunch of ILX: ids in core?
       -- no, we can just insert the existing ids correctly and then we won't have to worry about it
       -- we just have to be careful in core that we are only inserting everything normalized to ILX: (which is already screwed up)
       -- the ontology_history table is where we can sustain multiple variants for reconciliation

       -- materialized_type integer not null,  -- object properties w/ transitivity etc make this more complex
       -- constraint pk__interlex_ids primary key (id)
);

/*
CREATE TABLE interlex_computed(
       -- this is the cache of the latest verion of the default view of a term
       -- triggers should be used to update this
       -- alternately this is implemented in elasticsearch
);
*/

CREATE TABLE qualifiers(
       -- examples: 'reasoned by elk', 'loaded from uberon', 'submitted by user', 'reasonable subset'
       -- this table probably should not be used to track individual edits by users
       -- it may be used to track _all_ edits by a given user
       -- on the other hand logically it is one reasonable way to manage this, assuming that
       -- users aren't making millions of changes all the time
       -- if they are, then we could enable this as a 'version control' paradigm
       -- id serial primary key,  -- 9.x version
       id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- preferred for 10+
       group_id integer NOT NULL,  -- FIXME we only need this on source qualifiers? or what does source mean?
       -- name -- not clear that we need this
       datetime timestamp DEFAULT CURRENT_TIMESTAMP,
       source_qualifier_id integer NOT NULL CHECK (source_qualifier_id <= id),  -- <= ok due to id being primary key
       -- e.g. the uberon.owl source qualifier ??  -- can be null because source qualifiers have no source
       previous_qualifier_id integer NOT NULL CHECK (previous_qualifier_id <= id),
       -- NOTE for completeness it would be great if it were possible to have more than one
       -- previous_qualifier_id per qualifier, they would have to be ranked to resolve precedence issues
       -- but once that has been resolved, then the system would work very, very much like git HRM

       -- following this chain is needed to gather all additions
       -- bnodes that have not changed retain their oldest qualifier and we traverse previous_qualifier to find them
       -- git_repository
       -- git_commit_hash
       -- constraint pk__qualifiers primary key (id),

       -- TODO can we allow multiple previous qualifiers? what are the use cases for this?
       -- esp for cases where we have a qualifier that comes from multiple prior source
       -- for example we have a user that wants the ObjectProperties from the latest uberon load but the
       -- AnnotationProperties from curated interlex and
       -- then they delete some of the triples in uberon and remove some annotations from interlex and add new ones
       -- if we want the output to have a single qualifier then in the deleted table we need
       -- to pair the previous uberon or the previous interlex for each triple but the 'current' can be the same
       -- for the additions if we want to know what they changed it 'from' and there is more than one intance
       -- of a predicate, e.g. hasDbXref then there is no easy nor obvious way to do this
       -- for qualifiers that have single triple deletions and additions the behavior is still non-obvious?
       -- let's say that I 'edit' an uberon object that has qid 100, then in my deleted I add
       -- the id for the deleted triple, 100, 1001 where 1001 is the qualifier for the result
       -- but what is the previous qualifier for 1001 and what do we do with it?

       CONSTRAINT fk__qualifiers__group_id__users FOREIGN key (group_id) REFERENCES groups (id) match simple,
       CONSTRAINT fk__qualifiers__source_qualifier__qualifiers FOREIGN key (source_qualifier_id)
                  REFERENCES qualifiers (id) match simple,
       CONSTRAINT fk__qualifiers__previous_qualifier__qualifiers FOREIGN key (previous_qualifier_id)
                  REFERENCES qualifiers (id) match simple
);

CREATE INDEX qualifiers_id_index ON qualifiers (id);

INSERT INTO qualifiers (id, group_id, source_qualifier_id, previous_qualifier_id) VALUES (0, 1, 0, 0);
       -- the root of all qualifiers has id 0 and is its own source and own previous and base as the group

CREATE FUNCTION create_group_qualifier() RETURNS trigger AS $create_group_qualifier$
       DECLARE
           prev_qual integer;
       BEGIN
           IF NOT EXISTS (SELECT * from qualifiers as q where q.group_id = NEW.id and q.source_qualifier_id = 0)
           THEN
                SELECT last_value INTO STRICT prev_qual FROM qualifiers_id_seq; -- FIXME bad, sequences are not transactional
                INSERT INTO qualifiers (group_id, source_qualifier_id, previous_qualifier_id) 
                VALUES (NEW.id, 0, prev_qual);
           END IF;
           RETURN NULL;
       END;
$create_group_qualifier$ language plpgsql;

CREATE TRIGGER create_user_qualifier AFTER INSERT ON users FOR EACH ROW EXECUTE PROCEDURE create_group_qualifier();
CREATE TRIGGER create_org_qualifier AFTER INSERT ON orgs FOR EACH ROW EXECUTE PROCEDURE create_group_qualifier();

CREATE TABLE current_qualifiers(
       id integer NOT NULL,
       previous_id_array integer[] NOT NULL  -- trigger on new qualifier creation to avoid recursive queries
       -- TODO rename qualifiers to qualifiers_history?
       -- this table will maintain the set of current qualifiers
       -- along with the relevant historical qualifiers?? or no...
       -- basically we have to maintain a set of current qualifiers for each user
       -- the other way to implement this would be to have the 'current' set be the
       -- user only qualifier with no datetime and then if we want to construct a
       -- historical view then we resolve the additions and deletions without having
       -- to make a full copy of the qualified graph every time
       -- essentially a qualified deletions table
);

CREATE TABLE deletions(
       -- this is an alternative to copying everything that _didnt_ change in order to
       -- keep track of the history
       -- we shouldn't need the user here since that can be tracked in qualifiers
       -- same with the date
       s uri NOT NULL,
       p uri NOT NULL,
       o text NOT NULL,  -- FIXME how to do either or...
       qualifier_id integer NOT NULL,  -- the qualifier where the triple has been removed
       previous_qualifier_id integer NOT NULL CHECK (previous_qualifier_id != qualifier_id),  -- the qualifier where the triple was last included
       CONSTRAINT fk__deletions__qualifier_id__qualifiers FOREIGN key (qualifier_id) REFERENCES qualifiers (id) match simple,
       CONSTRAINT fk__deletions__previous_qualifier_id__qualifiers FOREIGN key (previous_qualifier_id) REFERENCES qualifiers (id) match simple
);

CREATE TABLE core(
       -- this table holds all transformed (lifted) representations that are in interlex
       -- it should have no bnodes
       s uri NOT NULL,
       p uri NOT NULL,
       o text NOT NULL,  -- FIXME literals vs urirefs have a literals table that includes type and use SELECT UNION
       qualifier_id integer NOT NULL,
       transform_rule_id integer NOT NULL,
       CONSTRAINT pk__core PRIMARY key (s, p, o, qualifier_id),  -- TODO need transform id too?
       CONSTRAINT fk__core__qualifier_id__qualifiers FOREIGN key (qualifier_id) REFERENCES qualifiers (id) match simple
);


CREATE INDEX core_s_q_index ON core (s, qualifier_id);
CREATE INDEX core_q_index ON core (qualifier_id);
CREATE INDEX core_s_index ON core (s);
CREATE INDEX core_p_index ON core (p);  -- for pulling things out by type

CREATE TABLE predicate_cardinality(
       -- only include those predicates that actually have cardinality restraints
       -- NOTE: predicate serialization rules are trickier, it is likely that we would suggest owl:sameAs
       -- to /base/ or 
       p uri NOT NULL,
       cardinality integer NOT NULL  -- non zero positive
       -- constraint fk__predicate_cardinality__p__core foreign key (p) references core (p) match simple
       -- TODO not quite a fk more a 'make sure this in in there'
);

CREATE TABLE ontology_history(
       -- untransformed or ahere to the no-bnodes rule?
       s uri NOT NULL,
       p uri NOT NULL,
       o text NOT NULL,  -- FIXME
       qualifier_id integer NOT NULL,
       CONSTRAINT fk__ontology_history__qualifier_id__qualifiers FOREIGN key (qualifier_id) REFERENCES qualifiers (id) match simple
);

CREATE TABLE triples_uri(
       s uri NOT NULL,
       p uri NOT NULL,
       o uri NOT NULL,
       qualifier_id integer NOT NULL,
       CONSTRAINT pk__triples_uri PRIMARY key (s, p, o, qualifier_id),  -- TODO need transform id too?
       CONSTRAINT fk__triples_uri__qualifier_id__qualifiers FOREIGN key (qualifier_id) REFERENCES qualifiers (id) match simple
);

CREATE TABLE triples_literal(
       s uri NOT NULL,
       p uri NOT NULL,
       o text NOT NULL,
       qualifier_id integer NOT NULL,
       CONSTRAINT pk__triples_literal PRIMARY key (s, p, o, qualifier_id),  -- TODO need transform id too?
       CONSTRAINT fk__triples_literal__qualifier_id__qualifiers FOREIGN key (qualifier_id) REFERENCES qualifiers (id) match simple
);

CREATE TYPE node_type AS enum ('URIRef', 'Literal', 'BNode')

CREATE SEQUENCE IF NOT EXISTS unlifted_bnode_seq;

CREATE TABLE triples_unlifted(
       -- bnodes ahoy!
       -- the alternative is to store chunks of deterministic turtle?
       -- or to run graph isomorphism checks
       -- insert into unlifted_triples (p, o, o_type, head_bnode, qualifier_id)
       -- before insert 
       s integer NOT NULL,
       p uri NOT NULL,
       o text NOT NULL, -- cast bnodes to int
       o_type node_type NOT NULL,
       head_bnode NOT NULL,
       qualifier_id integer NOT NULL,
       CONSTRAINT fk__unlifted__qualifier_id__qualifiers FOREIGN key (qualifier_id) REFERENCES qualifiers (id) match simple
);

CREATE FUNCTION insert_unlifted() RETURNS trigger AS $insert_unlifted$
       BEGIN
           -- TODO I have no idea what the right way is to do this
           -- when I have a complete subgraph with random bnodes
           RETURN NULL;
       END;
$insert_unlifted$ language plpgsql;

CREATE TRIGGER insert_unlifted BEFORE INSERT ON unlifted_triples FOR EACH ROW EXECUTE PROCEDURE insert_unlifted;

CREATE TABLE complex_triples(
       s uri NOT NULL,
       p uri NOT NULL,
       complex_object_id integer NOT NULL,
       qualifier_id integer NOT NULL
);

CREATE TABLE complex_objects(
       -- objects that are more complex than triples without bnodes
       -- I think we may need one table per special interlex type
       -- which is extremely suboptimal
       -- id serial not null,
       id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- preferred for 10+
       transform_rule integer NOT NULL
       -- object_type enum not null,
       -- owl:equivalentClass
       -- owl:Restriction
       -- owl:intersectionOf
       -- rdf:List
);

-- create table prov();  -- what were you doing

CREATE TABLE user_uris(
       user_id integer NOT NULL,
       ilx_id char(7) NOT NULL,
       uri_path text NOT NULL,  -- uri? or does it have to be varchar?
       -- uri_full uri not null,  -- yes or no?
       -- branch_private default false  -- TOOD this needs to be managed elsewhere?
       -- terminal -> branch changes? one way to cope is always resolve /branch/ -> branch
       -- but then we have to know which are branches...
       -- unique on user_id ilx_id as discussed in the spec or what?
       CONSTRAINT fk__uris__user_id__users FOREIGN key (user_id) REFERENCES users (id) match simple,
       CONSTRAINT fk__uris__ilx_id__interlex_ids FOREIGN key (ilx_id) REFERENCES interlex_ids (id) match simple
);

CREATE TABLE uri_branches(
       -- uris that may or may not be resolvable but that users want to make private or other things
       -- things can only start private, they cannot be unprivated
       user_id integer NOT NULL,
       branch_path text NOT NULL,
       public boolean NOT NULL,
       CONSTRAINT fk__uri_branches__user_id__users FOREIGN key (user_id) REFERENCES users (id) match simple
);

CREATE FUNCTION branch_no_hide() returns trigger AS $branch_no_hide$
       BEGIN
           IF NEW.public THEN
              RAISE exception 'Branch % is already public, you cannot make it private!', NEW.branch_path;
           END IF;
           RETURN NULL;
       END;
$branch_no_hide$ language plpgsql;

CREATE TRIGGER branch_no_hide before update ON uri_branches FOR each row execute procedure branch_no_hide();

CREATE TABLE curies(
       -- computing curied representations can be quite expensive
       -- TODO this needs history of some kind for versions
       group_id integer NOT NULL, -- if the user has not set curies fail over to default user
       curie_prefix varchar(30) NOT NULL,  -- is case sensitive, validate against the w3c/ietf spec
       iri_prefix uri NOT NULL,
       -- TODO what uniqueness constraints are we going to impose here?
       CONSTRAINT pk__curies PRIMARY key (group_id, curie_prefix, iri_prefix),
       CONSTRAINT fk__curies__group_id__group FOREIGN key (group_id) REFERENCES groups (id) match simple
);

CREATE TABLE ontologies(
       -- id serial not null,  -- FIXME do we really need this? yes, it makes it easier to do manage export rules
       id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- preferred for 10+
       group_id integer NOT NULL,
       ont_path text NOT NULL,
       -- ont_full uri not null,  -- 
       -- TODO do we store the ontology annotation data as triples or what? like title etc
       -- we should just be able to store them using either the interlex id for the ontology (bad idea?)
       -- or using the full path to the ontology file, also a bad idea, so maybe assigning interlex ids to user
       -- ontologies isn't the worst idea? or maybe we need /base/ontologies/ilxont_1234567
       -- basically we need something that will let /own/other-user/ontologies/my/ont/bob.ttl to adjust iris correctly
       -- and still get all the relevant metadata, I think /user/ontologies/my/ont/bob.ttl will work since we can
       -- just use a replacement rule since we will know the full uri for the original source
       -- sujbect_qualifier integer not null,  -- this is probably too granular but the idea of subject qualifiers is useful
       -- constraint pk__ontologies primary key (id)
       CONSTRAINT fk__ontologies__group_id__group FOREIGN key (group_id) REFERENCES groups (id) match simple
);

CREATE TABLE export_rules(
       -- id serial not null,
       id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- preferred for 10+
       group_id integer NOT NULL,  -- less relevant but important for prov
       rule text NOT NULL,  -- FIXME TODO how to encode these? can we avoid parsing?
       CONSTRAINT fk__export_rules__group_id__groups FOREIGN key (group_id) REFERENCES groups (id) match simple
);

 -- TODO defining sources and auxilliary sources eg uberon.owl and uberon-bridge.ttl

CREATE TABLE existing_iris(
       -- note that this table does NOT enumerate any uri.interlex.org identifiers
       -- the default/curated user will be the fail over
       -- do we need exclude rules? latest + original user will always be inserted
       -- but do we really even need latest to be explicit here?
       ilx_id char(7) NOT NULL,
       iri uri NOT NULL CHECK (uri_host(iri) NOT LIKE '%interlex.org'),
       group_id integer NOT NULL,
       CONSTRAINT fk__existing_iris__ilx_id__interlex_ids FOREIGN key (ilx_id) REFERENCES interlex_ids (id) match simple,
       -- constraint fk__existing_iris__iri__core foreign key (iri) references core (s) match simple,
       -- TODO core (s) is not a valid fk spec, need to find the right way to do it
       CONSTRAINT fk__existing_iris__group_id__group FOREIGN key (group_id) REFERENCES groups (id) match simple,
       CONSTRAINT pk__existing_iris PRIMARY KEY (iri, group_id)
);

CREATE INDEX existing_iris_iri_group_id_index ON existing_iris (iri, group_id);

GRANT SELECT, INSERT ON ALL TABLES IN SCHEMA interlex TO "interlex-user";  -- tables includes views
GRANT USAGE ON ALL SEQUENCES IN SCHEMA interlex TO "interlex-user";

-- interlex-user interlex_test
/* tests */

INSERT INTO interlex_ids DEFAULT VALUES RETURNING id;

INSERT INTO existing_iris (ilx_id, iri, group_id) VALUES ('0000001', 'http://uri.neuinfo.org/nif/nifstd/birnlex_796', 1),
                                                         ('0000001', 'http://purl.obolibrary.org/obo/UBERON_0000955', 1);

INSERT INTO core (s, p, o, qualifier_id, transform_rule_id)
       -- seriously consider pre-truncating everything for performance issues
       -- even if it is using my compression version of ttlser... probabably better
       -- to use the standard curies though for human readability of the database
       -- on the other hand using the uri type sort of obviates the issue
       VALUES ('http://uri.neuinfo.org/nif/nifstd/birnlex_796',
               'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',
               'http://www.w3.org/2002/07/owl#Class', 0, 0),
              ('http://uri.interlex.org/base/ilx_0000001',
               'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',
               'http://www.w3.org/2002/07/owl#Class', 0, 0);
              ('http://purl.obolibrary.org/obo/UBERON_0000955',
               'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',
               'http://www.w3.org/2002/07/owl#Class', 0, 0),

INSERT INTO user_emails (user_id, email, email_primary) VALUES (9, 'tgbugs@gmail.com', true);
INSERT INTO user_orcid (user_id, orcid) VALUES (9, 'https://orcid.org/0000-0002-7509-4801');

INSERT INTO orgs VALUES (idFromGroupname('uberon'), 'uberon', 9);

DELETE FROM orgs WHERE orgname = 'uberon';

select * from user_emails;
select * from user_orcid;
select * from users;

UPDATE user_emails SET email_validated = true; -- shouldn't actually be able to do this directly?

UPDATE user_orcid SET orcid_validated = true; -- shouldn't actually be able to do this directly?


 -- UPDATE new_users set email_validated = TRUE WHERE id = 9;
 -- UPDATE new_users set orcid_validated = TRUE WHERE id = 9;

 -- failing tests

INSERT INTO existing_iris VALUES ('0000001', 'http://uri.interlex.org/test', 9);
INSERT INTO existing_iris VALUES ('0000001', 'http://curies.interlex.org/test:', 9);

-- old
/*
*/

CREATE TABLE entities(
       id serial NOT NULL,  /* forget the past... */
       -- defining_iri_id  -- aka canonical interlex identifier, failover logic for users would thus go to the user namespace for the defining iri unless otherwise specified ... i think this is sane default behavior FIXME this fails because iris -> ents
       -- when creating a defining entity the best logical way to deal with this will be to create
       CONSTRAINT entities_pkey PRIMARY key (id)
);

CREATE TABLE entity_ilx_id(
       -- ok dont forget the past...
       entity_id integer NOT NULL,
       interlex_id integer NOT NULL,  -- FIXME string(7) ?? the rules for generating this are super annoying and locking issues
       -- FIXME interaction between this and the iris table is a problem...
       CONSTRAINT entity_ilx_id_pkey PRIMARY key (entity_id interlex_id)
);

CREATE TABLE external_sources(  -- sources?? including interlex + user?
       iri varchar() NOT NULL,
       CONSTRAINT external_sources_pkey PRIMARY KEY (iri)
);

CREATE TABLE external_iris(
       -- existing iris -> entities
       -- FIXME there are cases where another ontology will have merged terms... in which case we need a way to determine which are cross references and which will be the primary record... DERP
       -- only expected entities
       id serial NOT NULL,

       iri varchar() NOT NULL,  -- or uri... using the uri plugin
       entity_id integer NOT NULL,  -- map to entity, obvs will have to create a new entity if none exists
       user_id integer NOT NULL, -- qualify mapping per user default will have all of them and we will only add if user changes
       user_preference_for_triples varchar(),
       /* this is the correct place to store per user information about how to 
       include
       exclude*/

       UNIQUE (iri entity_id user_id),  -- only one mapping per user and some iris cannot be remapped ie the interlex one... ah that problem again
       constrain iris_pkey PRIMARY KEY (id),
       -- CONSTRAINT iris_pkey PRIMARY KEY (iri entity_id user_id)  -- only one mapping per user
       CONSTRAINT asdf FOREIGN KEY (entity_id) REFERENCES entities (id) MATCH SIMPLE,
       CONSTRAINT asdf1 FOREIGN KEY (user_id) REFERENCES users (id) MATCH SIMPLE
);

CREATE TABLE user_iri_behavior(
       -- the more granular version for control beyond settings afforded by isDefinedBy
       -- an enum table...?
       VALUE string(20)
       /*
       include  this is the implicit default and will not be added to the table
       exclude
       export as 
       merge all triples to
       use this one and add equivalences
       */

       -- the orthogonal dimensions, yes this is really a decision tree
       include-exclude -- include exclude xref has alternlate etc.
       subjects -- convert subjects in all triples with a subject that is an existing id for this entity to the preferred iri
                -- sameAs triples between all included existing ids
                -- equivalentClass triples between all included existing ids
                -- ilxEquivalent triples between all included existing ids
                -- see `predicate choices` section of the design doc for the predicate angle
                   -- do the 4 above for annotation properties, object properties, etc., or some subset of them
);

CREATE TABLE predicate_rules();
CREATE TABLE user_predicate_rules();
CREATE TABLE user_source_sets();
CREATE TABLE user_triple_sets();

CREATE TABLE user_preferred_iri(  -- we cannot shove iri behavior in here the primary key constraint imposes an important invariant
       entity_id integer,
       user_id integer,
       iri varchar(),
       CONSTRAINT upi_pkey PRIMARY KEY (entity_id user_id),
       CONSTRAINT asdf FOREIGN KEY (entity_id) REFERENCES entities (id) MATCH SIMPLE,
       CONSTRAINT asdf1 FOREIGN KEY (user_id) REFERENCES users (id) MATCH SIMPLE,
       CONSTRAINT asdf2 FOREIGN KEY (iri) REFERENCES external_iris (iri) MATCH SIMPLE
);

CREATE TABLE triples(
       id SERIAL NOT NULL, -- for convenience...
       s NOT NULL, -- FIXME we need to save the 'original' subject, but qualified entities want to collapse them...
       p NOT NULL,
       o NOT NULL,
       -- lift to restriction? someValueFrom allValueFrom
       CONSTRAINT triples_pkey PRIMARY KEY (id),
       UNIQUE (s p o),
       CONSTRAINT s_fkey FOREIGN KEY (iri) REFERENCES external_iris (iri) MATCH SIMPLE,
       CONSTRAINT p_fkey FOREIGN KEY (iri) REFERENCES external_iris (iri) MATCH SIMPLE
       );

CREATE TABLE qualified_entities(
       entity_id
       user_id
       version_id  -- entity version id...
       triple_id
);

CREATE TABLE qualified_triples(  -- FIXME I don't think we want this... we want qualified entities...
       -- this coudl end up becoming the HUGE qualified history table...
       -- we want to architect this so as to minimize the number of updates needed when a value is changed...
       -- maybe make this a sparse table?
       triple_id interger NOT NULL,
       isDefinedBy varchar(), -- here we keep the record of all the sources that have defined this triple including interlex, ontologyiri versionIRI github with commit etc... 
       -- user_id integer,
       -- user_version_id integer,  -- aka view version id since the 'user' abstraction will also apply to orgs/sources
       CONSTRAINT asdf1 FOREIGN KEY (user_id) REFERENCES users (id) MATCH SIMPLE,
       CONSTRAINT t_fkey FOREIGN KEY (triple_id) REFERENCES triples (id) MATCH SIMPLE,
       CONSTRAINT idb_fkey FOREIGN KEY (isDefinedBy) REFERENCES external_sources (iri) MATCH SIMPLE -- FIXME this needs to be a check constraint that either looks here or makes sure that it references an interlex user namespace iri...
);

-- extra...

CREATE TABLE user_version(
       user_id
       version_number
       forked_from
       CONSTRAINT asdf1 FOREIGN KEY (user_id) REFERENCES users (id) MATCH SIMPLE
)

CREATE TABLE qualified_user_versions(
       user_id
       triple_id
       version_number
       REFERENCES triples (id)
);

/* this approach does not work
create table annotations(
       eid
       atype
       value
);
create table dataproperties(
       eid
       atype
       value
);
create table relations(
       eid
       atype
       value
);
*/
